{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"k4hd7OaOFqYm","pycharm":{"name":"#%% md\n"}},"source":["# Filtracja Non-Local Means\n","\n","## Definicja\n","\n","Kolejny \"poziom wtajemniczenia\" w zagadnienie filtracji obrazów to metoda Non-Local Means (NLM).\n","Została ona zaproponowana w pracy *A non-local algorithm for image denoising* autorstwa Antoni Buades, Bartomeu Coll, i Jean Michel Morel na konferencji CVPR w 2005 roku.\n","\n","Filtr NLM dany jest zależnością:\n","\n","\\begin{equation}\n","\\hat{I}(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in V(\\mathbf{x})} w(\\mathbf{p},\\mathbf{x})I(\\mathbf{p})\n","\\end{equation}\n","\n","gdzie:\n","- $I$ - obraz wejściowy,\n","- $\\hat{I}$ - obraz wyjściowy (przefiltrowany),\n","- $\\mathbf{x}$ - współrzędne piksela obrazu,\n","- $V(\\mathbf{x})$ - obszar poszukiwań piksela, dla którego przeprowadzana jest filtracja,\n","- $w$ - waga punktu $\\mathbf{p}$ z obszaru poszukiwań.\n","\n","Wróćmy na chwilę do filtracji bilateralnej. Tam waga danego piksela z kontekstu zależała od dwóch czynników - odległości przestrzennej pomiędzy pikselami oraz różnicy w jasności/kolorze pomiędzy pikselami (tzw. przeciwdziedzina).\n","Filtr NLM stanowi uogólnienie tej metody - do obliczania wag nie wykorzystuje się już pojedynczych pikseli ($\\mathbf{p}$ i $\\mathbf{x}$), a lokalne konteksty ($N(\\mathbf{p})$ i $N(\\mathbf{x})$).\n","\n","Waga $w$ dana jest następującą zależnością:\n","\n","\\begin{equation}\n","w(\\mathbf{p},\\mathbf{x}) = \\frac{1}{Z(\\mathbf{x})}\\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n","\\end{equation}\n","\n","gdzie:\n","- \\begin{equation}\n","Z(\\mathbf{x}) = \\sum_{\\mathbf{p} \\in  V(\\mathbf{x})} \\exp(-\\frac{|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||^2_{2}}{\\alpha \\sigma^2})\n","\\end{equation},\n","- $|| \\cdot ||$ - jest normą $L_2$ odległości pomiędzy dwoma kontekstami,\n","- $v$ oznacza mnożenie punktowe kontekstu $N$ przez dwuwymiarową maskę Gaussa o odpowiadających kontekstowi wymiarach,\n","- $\\alpha$ > 0 - parametr sterujący filtracją,\n","- $\\sigma$ - parametr szumu stacjonarnego występującego na obrazie (w przypadku szumu niestacjonarnego, parametr $\\sigma$ musi zostać dopasowany lokalnie tj. $\\sigma = \\sigma(\\mathbf{x})$)."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"ipnn3yBGFqYp"},"source":["## Analiza działania\n","\n","Zastanówmy sie teraz jak działa filtra NLM. Najprościej to zrozumieć na rysunku.\n","\n","![Ilustracja NLM](https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/nlm.png)\n","\n","1. Dla rozważanego piksela $\\mathbf{x}$ definiujemy obszar poszukiwań $V(\\mathbf{x})$. Uwaga - obszar poszukiwań ($V$) jest jednostką większą niż otocznie/kontekst ($N$).\n","\n","2. Następnie, dla każdego z pikseli $\\mathbf{p} \\in  V(\\mathbf{x})$ oraz samego $\\mathbf{x}$ definiujemy otocznie/kontekst odpowiednio $N(\\mathbf{p})$ i $N(\\mathbf{x})$.\n","\n","3. Wracamy do równania definiującego wagę  $w(\\mathbf{p},\\mathbf{x})$, a konkretnie do wyrażenia $|| v(N(\\mathbf{p})) - v(N(\\mathbf{x})) ||$. Przeanalizujmy co ono oznacza. Mamy dwa otoczenia: $N(\\mathbf{p})$ i $N(\\mathbf{x})$. Każde z nich mnożymy przez odpowiadającą maskę Gaussa - funkcja $v$. Otrzymujemy dwie macierze, które odejmujemy od siebie punktowo. Następnie obliczamy kwadrat z normy ($L_2$ definiujemy jako $||X||_2 = \\sqrt{\\sum_k|X_k|^2}$. Otrzymujemy zatem jedną liczbę, która opisuje nam podobieństwo otoczeń pikseli $\\mathbf{x}$ i $\\mathbf{p}$. Mała wartość oznacza otoczenia zbliżone, duża - różniące się. Ponieważ, z dokładnością do stałych, liczba ta stanowi wykładnik funkcji $e^{-x}$, to ostatecznie waga jest zbliżona do 1 dla otoczeń podobnych, a szybko maleje wraz z malejącym podobieństwem kontekstów.\n","\n","4. Podsumowując. Jak wynika z powyższej analizy filtr NLM to taki filtr bilateralny, w którym zamiast pojedynczych pikseli porównuje się ich lokalne otoczenia. Wpływa to pozytywnie na jakość filtracji, niestety kosztem złożoności obliczeniowej."]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"hdcd4-c8FqYr","pycharm":{"name":"#%% md\n"}},"source":["## Implementacja\n","\n","W ramach zadania należy zaimplementować filtr NLM, ocenić jego działanie w porównaniu do filtra Gaussa i bilateralnego oraz dokonać pomiaru czasu obliczeń (dla trzech wymienionych metod).\n","\n","Jak już się zrozumie jak działa NLM, jego implementacja jest dość prosta.\n","Wartość parametru $\\alpha$ należy dobrać eksperymentalnie.\n","Nie należy także \"przesadzić\" z rozmiarem obszaru poszukiwań (np. 11x11) oraz kontekstu (5x5 lub 3x3).\n","\n","Wskazówki do implementacji:\n","- algorytm sprowadza się do dwóch podwójnych pętli for: zewnętrzne po pikselach, wewnętrzne po kolejnych obszarach przeszukań,\n","- przed realizacją trzeba przemyśleć problem pikseli brzegowych - de facto problemów jest kilka. Po pierwsze nie dla każdego piksela można wyznaczyć pełny obszar przeszukań (tu propozycja, aby filtrację przeprowadzać tylko dla pikseli z pełnym obszarem). Po drugie, ponieważ rozpatrujemy konteksty, to nawet dla piksela o \"pełnym\" obszarze przeszukań, będą istnieć piksele, dla których nie pełnych kontekstów (sugestia - powiększyć obszar przeszukać, tak aby zawierał konteksty). Ostatni problem jest bardziej techniczny/implementacyjny. Jeśli w kolejnych iteracjach \"jawnie\" wytniemy fragment o rozmiarach obszaru przeszukiwań, to znowu pojawi się problem brzegowy - tu można albo wyciąć nieco większy obszar, albo cały czas \"pracować\" na obrazie oryginalnym (\"żonglerka indeksami\").\n","- warto sprawdzać indeksy i rozmiary \"wycinanych\" kontekstów,\n","- wagi wyliczamy w trzech krokach:\n","    - obliczenia dla $N(\\mathbf{x})$ + inicjalizacja macierzy na wagi,\n","    - podwójna pętla, w której przeprowadzamy obliczenia dla kolejnych $N(\\mathbf{p})$ oraz wyliczamy wagi,\n","    - normalizacja macierzy wag oraz końcowa filtracja obszaru w wykorzystaniem wag.\n","- uwaga, obliczenia trochę trwają, nawet dla obrazka 256x256 i względnie niewielkich obszaru przeszukań i kontesktu.\n","\n","Efekt końcowy:\n","- porównanie wyników metod: filtr Gaussa, filtr bilateralny oraz filtr NLM (2-3 zdania komentarza),\n","- porównanie czasu działania powyższych metod (1 zdanie komentarza).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yd6FHw0uFqYs","pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import cv2\n","import os\n","import requests\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from scipy import signal\n","from scipy.io import loadmat\n","import math\n","\n","url = 'https://raw.githubusercontent.com/vision-agh/poc_sw/master/07_Bilateral/'\n","\n","fileNames = [\"MR_data.mat\"]\n","for fileName in fileNames:\n","  if not os.path.exists(fileName):\n","      r = requests.get(url + fileName, allow_redirects=True)\n","      open(fileName, 'wb').write(r.content)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def gaussian_filter(window_size, wariancja):\n","    kernel = np.fromfunction(\n","        lambda x, y: (1/(2*np.pi*wariancja**2)) * \n","                     np.exp(-((x-(window_size-1)/2)**2 + (y-(window_size-1)/2)**2) / (2*wariancja**2)),\n","        (window_size, window_size)\n","    )\n","    return kernel / np.sum(kernel)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def classic_conv(img, window, sigma):\n","    kernel = gaussian_filter(window, sigma)\n","    image = img.copy()\n","    height, width = image.shape\n","    img_with_padding = np.zeros((height + window - 1, width + window - 1))\n","    img_with_padding[(window - 1) // 2 : -(window - 1) // 2, (window - 1) // 2 : -(window - 1) // 2] = image\n","\n","    output_img = np.zeros_like(image)\n","\n","    for i in range(0, height):\n","        for j in range(0, width):\n","            output_img[i, j] = (kernel * img_with_padding[i : i + window, j : j + window]).sum()\n","    return output_img"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def new_pixel_value(img, context, window, sigma, x_, y_, gauss):\n","    new_window = 0\n","    new_value = 0\n","    for i in range(window):\n","        for j in range(window):\n","            light_diff = np.abs(int(context[i, j]) - int(img[x_, y_])).astype(np.int8)\n","            gamma = (\n","                np.exp((-1) * (((light_diff) ** 2) / (2 * (sigma**2))))\n","                * gauss[i, j]\n","                )\n","            new_window += gamma\n","            new_value += gamma * context[i, j]\n","    new_value = new_value / new_window if new_window != 0 else 0\n","    return new_value\n","\n","def bilateral_conv(image, okno: int, sigma: float, sigma_r: float):\n","    height, width = image.shape\n","    result = np.zeros((height, width))\n","    size = okno // 2\n","    gauss = gaussian_filter(okno, sigma)\n","    for i in range(size, height - size):\n","        for j in range(size, width - size):\n","            context = image[i - size : i + size + 1, j - size : j + size + 1]\n","            result[i, j] = new_pixel_value(image, context, okno, sigma_r, i, j, gauss)\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def non_local_means(img, zakres_obszaru:int, okno: int, alpha: float, sigma: float):\n","    img = img.astype(np.float64)\n","    zakres_obszaru += okno // 2 * 2  \n","    height, width = img.shape\n","    call_gaus = lambda x: gaussian_filter(okno, sigma) * x\n","    image = np.zeros(img.shape)\n","    for x in range(zakres_obszaru // 2, height - zakres_obszaru // 2):\n","        for y in range(zakres_obszaru // 2, width - zakres_obszaru // 2):\n","\n","            obszar_V = img[x - zakres_obszaru // 2 : x + zakres_obszaru // 2 + 1, y - zakres_obszaru // 2 : y + zakres_obszaru // 2 + 1]\n","            nowe_okno = np.array([])\n","            Nx = img[x - okno // 2 : x + okno // 2 + 1, y - okno // 2 : y + okno // 2 + 1]\n","            obszar_V_height, obszar_V_width = obszar_V.shape\n","            for s in range(okno // 2, obszar_V_height - okno // 2):\n","                for z in range(okno // 2, obszar_V_width - okno // 2):\n","                    \n","                    Np = obszar_V[s - okno // 2 : s + okno // 2 + 1, z - okno // 2 : z + okno // 2 + 1]\n","                    Wexp = np.exp(\n","                        -np.sum((call_gaus(Np) - call_gaus(Nx)) ** 2) / (alpha * sigma**2)\n","                    )\n","                    nowe_okno = np.append(nowe_okno, Wexp)\n","            W = nowe_okno / np.sum(nowe_okno)\n","            I = obszar_V[okno // 2 : -(okno // 2), okno // 2 : -(okno // 2)]\n","            image[x, y] = np.sum(W.reshape(I.shape) * I)\n","    max_ = max(image.flatten())\n","\n","    return (image / max_ * 255).astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#porownanie z pozostałymi funkcjami\n","MR_data = loadmat('MR_data.mat')\n","img = MR_data['I_noisy1'].copy()\n","_, ax = plt.subplots(1, 4, figsize=(15, 10))\n","ax[0].imshow(img, cmap='gray')\n","ax[0].set_title('Original')\n","start_time = cv2.getTickCount()\n","ax[1].imshow(classic_conv(img, 7, 1), cmap='gray')\n","ax[1].set_title('Classic')\n","print('Classic convolution time: ', (cv2.getTickCount() - start_time) / cv2.getTickFrequency())\n","start_time = cv2.getTickCount()\n","ax[2].imshow(bilateral_conv(img, 7, 1, 1), cmap='gray')\n","ax[2].set_title('Biateral')\n","print('Bilateral convolution time: ', (cv2.getTickCount() - start_time) / cv2.getTickFrequency())\n","start_time = cv2.getTickCount()\n","ax[3].set_title('Non local means')\n","ax[3].imshow(non_local_means(img, 7, 7, 1, 1), cmap='gray')\n","print('Non local means convolution time: ', (cv2.getTickCount() - start_time) / cv2.getTickFrequency())\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
